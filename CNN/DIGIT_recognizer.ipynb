{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"../DataSets/Digitrecognizer/\"\n",
    "train_data = pd.read_csv(root+'train.csv',dtype=np.float32)\n",
    "test_data = pd.read_csv(root+'test.csv',dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Dataset\n",
    "* What we are doing here is taking the raw dataset and splitting into targets and features. Dividing by 255 makes each pixel value to scale between 0 and 1 instead of 0 and 255, which helps in training our model. This step in Machine Learning is generally known as Normalization. Then we split into train and test sets using sklearn's train_test_split function.\n",
    "\n",
    "* Converting the numpy arrays into PyTorch Tensors using from_numpy function.\n",
    "\n",
    "* Batch size is set. The batch size is usually set between 64 and 256. The batch size does have an effect on the final test accuracy. One way to think about it is that smaller batches means that the number of parameter updates per epoch is greater. \n",
    "\n",
    "* To pass our data into our PyTorch models we need to convert it to a PyTorch Dataset. A Tensor Dataset in this case. \n",
    "\n",
    "* We have the training data loaded into trainloader and we can make an iterator with iter(trainloader) that can help us grab data. Later, we'll use this to loop through the dataset for training. Each time we can pull out data of the size of the batch that is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_data.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_data.loc[:,train_data.columns!='label'].values/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(features,target,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33600"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = torch.from_numpy(X_train)\n",
    "train_labels = torch.from_numpy(Y_train).type(torch.LongTensor)\n",
    "\n",
    "test_inputs = torch.from_numpy(X_test)\n",
    "test_labels = torch.from_numpy(Y_test).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size\n",
    "batch_size = 256\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(train_inputs,train_labels)\n",
    "test = torch.utils.data.TensorDataset(test_inputs,test_labels)\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ANN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANN,self).__init__()\n",
    "        # input_features = 28*28*1\n",
    "        self.fc1 = nn.Linear(28*28*1,392)\n",
    "        self.fc2 = nn.Linear(392,196)\n",
    "        self.fc3 = nn.Linear(196,98)\n",
    "        self.fc4 = nn.Linear(98,49)\n",
    "        self.fc5 = nn.Linear(49,10)\n",
    "        self.log_softmax = nn.functional.log_softmax\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.relu(self.fc3(x))\n",
    "        x = nn.functional.relu(self.fc4(x))\n",
    "        out = self.log_softmax(self.fc5(x),dim=1)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0015\n",
    "batch_size = 100\n",
    "training_epochs = 25\n",
    "ANN_model = ANN()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(ANN_model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of epoch 1 started\n",
      "[Epoch: 1   ] cost = 0.806 took 4.7764036655426025s\n",
      "Training of epoch 2 started\n",
      "[Epoch: 2   ] cost = 0.274 took 2.4843552112579346s\n",
      "Training of epoch 3 started\n",
      "[Epoch: 3   ] cost = 0.172 took 2.4743828773498535s\n",
      "Training of epoch 4 started\n",
      "[Epoch: 4   ] cost = 0.128 took 2.240009069442749s\n",
      "Training of epoch 5 started\n",
      "[Epoch: 5   ] cost = 0.0924 took 2.3586924076080322s\n",
      "Training of epoch 6 started\n",
      "[Epoch: 6   ] cost = 0.0727 took 2.734686851501465s\n",
      "Training of epoch 7 started\n",
      "[Epoch: 7   ] cost = 0.0566 took 2.6249911785125732s\n",
      "Training of epoch 8 started\n",
      "[Epoch: 8   ] cost = 0.0425 took 2.607027292251587s\n",
      "Training of epoch 9 started\n",
      "[Epoch: 9   ] cost = 0.0328 took 2.5162792205810547s\n",
      "Training of epoch 10 started\n",
      "[Epoch: 10  ] cost = 0.0313 took 2.371657371520996s\n",
      "Training of epoch 11 started\n",
      "[Epoch: 11  ] cost = 0.0279 took 2.359689235687256s\n",
      "Training of epoch 12 started\n",
      "[Epoch: 12  ] cost = 0.0272 took 2.6359503269195557s\n",
      "Training of epoch 13 started\n",
      "[Epoch: 13  ] cost = 0.0252 took 2.598050594329834s\n",
      "Training of epoch 14 started\n",
      "[Epoch: 14  ] cost = 0.0211 took 2.7436623573303223s\n",
      "Training of epoch 15 started\n",
      "[Epoch: 15  ] cost = 0.024 took 2.910217761993408s\n",
      "Training of epoch 16 started\n",
      "[Epoch: 16  ] cost = 0.00925 took 2.682823657989502s\n",
      "Training of epoch 17 started\n",
      "[Epoch: 17  ] cost = 0.0257 took 2.7127459049224854s\n",
      "Training of epoch 18 started\n",
      "[Epoch: 18  ] cost = 0.00677 took 2.625977039337158s\n",
      "Training of epoch 19 started\n",
      "[Epoch: 19  ] cost = 0.0129 took 2.8503777980804443s\n",
      "Training of epoch 20 started\n",
      "[Epoch: 20  ] cost = 0.0136 took 2.5800998210906982s\n",
      "Training of epoch 21 started\n",
      "[Epoch: 21  ] cost = 0.0144 took 2.517268180847168s\n",
      "Training of epoch 22 started\n",
      "[Epoch: 22  ] cost = 0.0075 took 2.4554333686828613s\n",
      "Training of epoch 23 started\n",
      "[Epoch: 23  ] cost = 0.0126 took 2.7157394886016846s\n",
      "Training of epoch 24 started\n",
      "[Epoch: 24  ] cost = 0.00724 took 2.637946128845215s\n",
      "Training of epoch 25 started\n",
      "[Epoch: 25  ] cost = 0.0156 took 2.5631449222564697s\n",
      "Learning Finished! in 66.84141254425049s\n"
     ]
    }
   ],
   "source": [
    "training_time = time.time()\n",
    "for epochs in range(training_epochs):\n",
    "    print(\"Training of epoch {} started\".format(epochs+1))\n",
    "    avg_cost = 0\n",
    "    total_batch = len(X_train)//batch_size\n",
    "    start_time = time.time()\n",
    "    for inputs,labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = ANN_model(inputs)\n",
    "        loss = criterion(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_cost+=loss.data / batch_size\n",
    "    print(\"[Epoch: {:<4}] cost = {:_<4.3} took {}s\".format(epochs + 1, avg_cost.item(),time.time()-start_time))\n",
    "\n",
    "print('Learning Finished! in {}s'.format(time.time()-training_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our model on test set using ANN architecture is  tensor(97.0771)\n"
     ]
    }
   ],
   "source": [
    "# Turn off gradients for validation\n",
    "test_loss = 0\n",
    "accuracy = 0\n",
    "with torch.no_grad():\n",
    "    ANN_model.eval()\n",
    "for images, labels in test_loader:\n",
    "    log_ps = ANN_model(images)\n",
    "    test_loss += criterion(log_ps, labels)\n",
    "\n",
    "    ps = torch.exp(log_ps)\n",
    "    # Get our top predictions\n",
    "    top_p, top_class = ps.topk(1, dim=1)\n",
    "    equals = top_class == labels.view(*top_class.shape)\n",
    "    accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "print(\"Accuracy of our model on test set using ANN architecture is \", (accuracy/len(test_loader))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target1 = target\n",
    "features1 = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784)  to  (42000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "features1 = features.reshape(features.shape[0],1,28,28)\n",
    "print(features.shape,\" to \",features1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1,X_test1,Y_train1,Y_test1 = train_test_split(features1,target1,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting numpy array to tensor\n",
    "train_inputs1 = torch.from_numpy(X_train1)\n",
    "train_labels1 = torch.from_numpy(Y_train1).type(torch.LongTensor)\n",
    "\n",
    "test_inputs1 = torch.from_numpy(X_test1)\n",
    "test_labels1 = torch.from_numpy(Y_test1).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size\n",
    "batch_size = 256\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train1 = torch.utils.data.TensorDataset(train_inputs1,train_labels1)\n",
    "test1 = torch.utils.data.TensorDataset(test_inputs1,test_labels1)\n",
    "\n",
    "# data loader\n",
    "train_loader1 = torch.utils.data.DataLoader(train1, batch_size = batch_size, shuffle = True)\n",
    "test_loader1 = torch.utils.data.DataLoader(test1, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(in_channels=1,out_channels=32,kernel_size=5,stride=1,padding=2),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(stride=2,kernel_size=2))\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=1),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(kernel_size=2,stride=2))\n",
    "        self.fc1 = nn.Linear(in_features=7*7*64,out_features=1500)\n",
    "        self.fc2 = nn.Linear(in_features=1500,out_features=800)\n",
    "        self.fc3 = nn.Linear(800,400)\n",
    "        self.fc4 = nn.Linear(400,100)\n",
    "        self.fc5 = nn.Linear(100,10)\n",
    "        self.softmax = nn.functional.log_softmax\n",
    "        nn.init.xavier_uniform_(self.fc5.weight)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.relu(self.fc3(x))\n",
    "        x = nn.functional.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        out = self.softmax(x,dim=1)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0015\n",
    "batch_size = 256\n",
    "training_epochs = 50\n",
    "CNN_model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(CNN_model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of epoch 1 started\n",
      "[Epoch: 1   ] cost = 0.00322 took 70.86893463134766s\n",
      "Training of epoch 2 started\n",
      "[Epoch: 2   ] cost = 0.00325 took 77.6385223865509s\n",
      "Training of epoch 3 started\n",
      "[Epoch: 3   ] cost = 0.00533 took 78.26769828796387s\n",
      "Training of epoch 4 started\n",
      "[Epoch: 4   ] cost = 0.00341 took 81.65342402458191s\n",
      "Training of epoch 5 started\n",
      "[Epoch: 5   ] cost = 0.00341 took 79.82010436058044s\n",
      "Training of epoch 6 started\n",
      "[Epoch: 6   ] cost = 0.00237 took 87.53954267501831s\n",
      "Training of epoch 7 started\n",
      "[Epoch: 7   ] cost = 0.00342 took 64.5513744354248s\n",
      "Training of epoch 8 started\n",
      "[Epoch: 8   ] cost = 0.00361 took 82.22186398506165s\n",
      "Training of epoch 9 started\n",
      "[Epoch: 9   ] cost = 0.000672 took 84.16724395751953s\n",
      "Training of epoch 10 started\n",
      "[Epoch: 10  ] cost = 0.00324 took 82.8834547996521s\n",
      "Training of epoch 11 started\n",
      "[Epoch: 11  ] cost = 0.00256 took 78.45534038543701s\n",
      "Training of epoch 12 started\n",
      "[Epoch: 12  ] cost = 0.00213 took 81.15192866325378s\n",
      "Training of epoch 13 started\n",
      "[Epoch: 13  ] cost = 0.000429 took 82.97196316719055s\n",
      "Training of epoch 14 started\n",
      "[Epoch: 14  ] cost = 0.00344 took 79.01397728919983s\n",
      "Training of epoch 15 started\n",
      "[Epoch: 15  ] cost = 0.00348 took 78.58295822143555s\n",
      "Training of epoch 16 started\n",
      "[Epoch: 16  ] cost = 0.00159 took 82.4549913406372s\n",
      "Training of epoch 17 started\n",
      "[Epoch: 17  ] cost = 0.00243 took 76.95422410964966s\n",
      "Training of epoch 18 started\n",
      "[Epoch: 18  ] cost = 0.00165 took 73.60908246040344s\n",
      "Training of epoch 19 started\n",
      "[Epoch: 19  ] cost = 0.00343 took 75.86866116523743s\n",
      "Training of epoch 20 started\n",
      "[Epoch: 20  ] cost = 0.00188 took 79.13964772224426s\n",
      "Training of epoch 21 started\n",
      "[Epoch: 21  ] cost = 0.0013 took 75.59182024002075s\n",
      "Training of epoch 22 started\n",
      "[Epoch: 22  ] cost = 0.00322 took 83.95195841789246s\n",
      "Training of epoch 23 started\n",
      "[Epoch: 23  ] cost = 0.00238 took 81.3320665359497s\n",
      "Training of epoch 24 started\n",
      "[Epoch: 24  ] cost = 0.00196 took 84.79825496673584s\n",
      "Training of epoch 25 started\n",
      "[Epoch: 25  ] cost = 0.00158 took 79.95459365844727s\n",
      "Learning Finished! in 1983.5273904800415s\n"
     ]
    }
   ],
   "source": [
    "training_time = time.time()\n",
    "for epochs in range(training_epochs):\n",
    "    print(\"Training of epoch {} started\".format(epochs+1))\n",
    "    avg_cost = 0\n",
    "    total_batch = len(X_train)//batch_size\n",
    "    start_time = time.time()\n",
    "    for inputs,labels in train_loader1:\n",
    "        optimizer.zero_grad()\n",
    "        output = CNN_model(inputs)\n",
    "        loss = criterion(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_cost+=loss.data/batch_size\n",
    "    print(\"[Epoch: {:<4}] cost = {:_<4.3} took {}s\".format(epochs + 1, avg_cost.item(),time.time()-start_time))\n",
    "\n",
    "print('Learning Finished! in {}s'.format(time.time()-training_time))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our model on test set using CNN architecture is  tensor(99.0357)\n"
     ]
    }
   ],
   "source": [
    "# Turn off gradients for validation\n",
    "test_loss1 = 0\n",
    "accuracy1 = 0\n",
    "with torch.no_grad():\n",
    "    CNN_model.eval()\n",
    "for images, labels in test_loader1:\n",
    "    out = CNN_model(images)\n",
    "    test_loss1 += criterion(out, labels)\n",
    "\n",
    "    ps = torch.exp(out)\n",
    "    # Get our top predictions\n",
    "    top_p, top_class = ps.topk(1, dim=1)\n",
    "    equals1 = top_class == labels.view(*top_class.shape)\n",
    "    accuracy1 += torch.mean(equals1.type(torch.FloatTensor))\n",
    "print(\"Accuracy of our model on test set using CNN architecture is \", (accuracy1/len(test_loader1))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type CNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(CNN_model,\"../DataSets/Kaggle/digitrecognizerCNN.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelreloaded = torch.load(\"../DataSets/Kaggle/digitrecognizerCNN.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_data.loc[:].values/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.reshape(len(test),1,28,28)\n",
    "test_tensor = torch.from_numpy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.utils.data.TensorDataset(test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = torch.utils.data.DataLoader(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DatasetSubmissionMNIST(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_path, transform=None):\n",
    "        self.data = pd.read_csv(file_path)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.data.iloc[index].values.astype(np.uint8).reshape((1, 28, 28))\n",
    "\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image\n",
    "\n",
    "\n",
    "\n",
    "submissionset = DatasetSubmissionMNIST('../DataSets/Digitrecognizer/test.csv')\n",
    "submissionloader = torch.utils.data.DataLoader(submissionset, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "_thnn_conv2d_forward not supported on CPUType for Byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-096159dc09b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msubmissionloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelreloaded\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mans\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-e11b9282afae>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[1;32m--> 338\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: _thnn_conv2d_forward not supported on CPUType for Byte"
     ]
    }
   ],
   "source": [
    "ans = torch.LongTensor()\n",
    "for img in submissionloader:\n",
    "    img = torch.autograd.Variable(img)\n",
    "    output = modelreloaded(img)\n",
    "    _,predicted = torch.max(output[0],1)\n",
    "    ans = torch.cat([ans,predicted.data],0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"./Digitrecognizer/\"\n",
    "train_data = pd.read_csv(root+'train.csv',dtype=np.float32)\n",
    "test_data = pd.read_csv(root+'test.csv',dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'pixel0', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5',\n",
       "       'pixel6', 'pixel7', 'pixel8',\n",
       "       ...\n",
       "       'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779',\n",
       "       'pixel780', 'pixel781', 'pixel782', 'pixel783'],\n",
       "      dtype='object', length=785)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28000 entries, 0 to 27999\n",
      "Columns: 784 entries, pixel0 to pixel783\n",
      "dtypes: int64(784)\n",
      "memory usage: 167.5 MB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Dataset\n",
    "* What we are doing here is taking the raw dataset and splitting into targets and features. Dividing by 255 makes each pixel value to scale between 0 and 1 instead of 0 and 255, which helps in training our model. This step in Machine Learning is generally known as Normalization. Then we split into train and test sets using sklearn's train_test_split function.\n",
    "\n",
    "* Converting the numpy arrays into PyTorch Tensors using from_numpy function.\n",
    "\n",
    "* Batch size is set. The batch size is usually set between 64 and 256. The batch size does have an effect on the final test accuracy. One way to think about it is that smaller batches means that the number of parameter updates per epoch is greater. \n",
    "\n",
    "* To pass our data into our PyTorch models we need to convert it to a PyTorch Dataset. A Tensor Dataset in this case. \n",
    "\n",
    "* We have the training data loaded into trainloader and we can make an iterator with iter(trainloader) that can help us grab data. Later, we'll use this to loop through the dataset for training. Each time we can pull out data of the size of the batch that is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_data.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_data.loc[:,train_data.columns!='label'].values/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(features,target,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33600"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = torch.from_numpy(X_train)\n",
    "train_labels = torch.from_numpy(Y_train).type(torch.LongTensor)\n",
    "\n",
    "test_inputs = torch.from_numpy(X_test)\n",
    "test_labels = torch.from_numpy(Y_test).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size\n",
    "batch_size = 256\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(train_inputs,train_labels)\n",
    "test = torch.utils.data.TensorDataset(test_inputs,test_labels)\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ANN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANN,self).__init__()\n",
    "        # input_features = 28*28*1\n",
    "        self.fc1 = nn.Linear(28*28*1,392)\n",
    "        self.fc2 = nn.Linear(392,196)\n",
    "        self.fc3 = nn.Linear(196,98)\n",
    "        self.fc4 = nn.Linear(98,49)\n",
    "        self.fc5 = nn.Linear(49,10)\n",
    "        self.log_softmax = nn.functional.log_softmax\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.relu(self.fc3(x))\n",
    "        x = nn.functional.relu(self.fc4(x))\n",
    "        out = self.log_softmax(self.fc5(x),dim=1)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0015\n",
    "batch_size = 100\n",
    "training_epochs = 25\n",
    "ANN_model = ANN()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(ANN_model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of epoch 1 started\n",
      "[Epoch: 1   ] cost = 0.822 took 2.118333101272583s\n",
      "Training of epoch 2 started\n",
      "[Epoch: 2   ] cost = 0.265 took 2.3626821041107178s\n",
      "Training of epoch 3 started\n",
      "[Epoch: 3   ] cost = 0.171 took 2.2400095462799072s\n",
      "Training of epoch 4 started\n",
      "[Epoch: 4   ] cost = 0.13 took 2.1273109912872314s\n",
      "Training of epoch 5 started\n",
      "[Epoch: 5   ] cost = 0.0931 took 2.118335723876953s\n",
      "Training of epoch 6 started\n",
      "[Epoch: 6   ] cost = 0.0797 took 2.477375030517578s\n",
      "Training of epoch 7 started\n",
      "[Epoch: 7   ] cost = 0.0597 took 2.352707862854004s\n",
      "Training of epoch 8 started\n",
      "[Epoch: 8   ] cost = 0.0479 took 2.3347561359405518s\n",
      "Training of epoch 9 started\n",
      "[Epoch: 9   ] cost = 0.0331 took 2.312814950942993s\n",
      "Training of epoch 10 started\n",
      "[Epoch: 10  ] cost = 0.0346 took 2.438478708267212s\n",
      "Training of epoch 11 started\n",
      "[Epoch: 11  ] cost = 0.0285 took 2.636948585510254s\n",
      "Training of epoch 12 started\n",
      "[Epoch: 12  ] cost = 0.0155 took 2.470393180847168s\n",
      "Training of epoch 13 started\n",
      "[Epoch: 13  ] cost = 0.0265 took 2.293865442276001s\n",
      "Training of epoch 14 started\n",
      "[Epoch: 14  ] cost = 0.0173 took 2.295860767364502s\n",
      "Training of epoch 15 started\n",
      "[Epoch: 15  ] cost = 0.0153 took 2.281897783279419s\n",
      "Training of epoch 16 started\n",
      "[Epoch: 16  ] cost = 0.0144 took 2.3148107528686523s\n",
      "Training of epoch 17 started\n",
      "[Epoch: 17  ] cost = 0.0189 took 2.3447301387786865s\n",
      "Training of epoch 18 started\n",
      "[Epoch: 18  ] cost = 0.0158 took 2.3547022342681885s\n",
      "Training of epoch 19 started\n",
      "[Epoch: 19  ] cost = 0.0161 took 2.2928671836853027s\n",
      "Training of epoch 20 started\n",
      "[Epoch: 20  ] cost = 0.0101 took 2.3068318367004395s\n",
      "Training of epoch 21 started\n",
      "[Epoch: 21  ] cost = 0.0176 took 2.230036735534668s\n",
      "Training of epoch 22 started\n",
      "[Epoch: 22  ] cost = 0.0169 took 2.3128154277801514s\n",
      "Training of epoch 23 started\n",
      "[Epoch: 23  ] cost = 0.0142 took 2.243001699447632s\n",
      "Training of epoch 24 started\n",
      "[Epoch: 24  ] cost = 0.0182 took 2.279902458190918s\n",
      "Training of epoch 25 started\n",
      "[Epoch: 25  ] cost = 0.00936 took 2.242004156112671s\n",
      "Learning Finished! in 57.8372962474823s\n"
     ]
    }
   ],
   "source": [
    "training_time = time.time()\n",
    "for epochs in range(training_epochs):\n",
    "    print(\"Training of epoch {} started\".format(epochs+1))\n",
    "    avg_cost = 0\n",
    "    total_batch = len(X_train)//batch_size\n",
    "    start_time = time.time()\n",
    "    for inputs,labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = ANN_model(inputs)\n",
    "        loss = criterion(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_cost+=loss.data / batch_size\n",
    "    print(\"[Epoch: {:<4}] cost = {:_<4.3} took {}s\".format(epochs + 1, avg_cost.item(),time.time()-start_time))\n",
    "\n",
    "print('Learning Finished! in {}s'.format(time.time()-training_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our model on test set using ANN architecture is  tensor(97.4587)\n"
     ]
    }
   ],
   "source": [
    "# Turn off gradients for validation\n",
    "test_loss = 0\n",
    "accuracy = 0\n",
    "with torch.no_grad():\n",
    "    ANN_model.eval()\n",
    "for images, labels in test_loader:\n",
    "    log_ps = ANN_model(images)\n",
    "    test_loss += criterion(log_ps, labels)\n",
    "\n",
    "    ps = torch.exp(log_ps)\n",
    "    # Get our top predictions\n",
    "    top_p, top_class = ps.topk(1, dim=1)\n",
    "    equals = top_class == labels.view(*top_class.shape)\n",
    "    accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "print(\"Accuracy of our model on test set using ANN architecture is \", (accuracy/len(test_loader))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "target1 = target\n",
    "features1 = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784)  to  (42000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "features1 = features.reshape(features.shape[0],1,28,28)\n",
    "print(features.shape,\" to \",features1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1,X_test1,Y_train1,Y_test1 = train_test_split(features1,target1,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting numpy array to tensor\n",
    "train_inputs1 = torch.from_numpy(X_train1)\n",
    "train_labels1 = torch.from_numpy(Y_train1).type(torch.LongTensor)\n",
    "\n",
    "test_inputs1 = torch.from_numpy(X_test1)\n",
    "test_labels1 = torch.from_numpy(Y_test1).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size\n",
    "batch_size = 256\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train1 = torch.utils.data.TensorDataset(train_inputs1,train_labels1)\n",
    "test1 = torch.utils.data.TensorDataset(test_inputs1,test_labels1)\n",
    "\n",
    "# data loader\n",
    "train_loader1 = torch.utils.data.DataLoader(train1, batch_size = batch_size, shuffle = True)\n",
    "test_loader1 = torch.utils.data.DataLoader(test1, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(in_channels=1,out_channels=32,kernel_size=5,stride=1,padding=2),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(stride=2,kernel_size=2))\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=1),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(kernel_size=2,stride=2))\n",
    "        self.fc1 = nn.Linear(in_features=7*7*64,out_features=1500)\n",
    "        self.fc2 = nn.Linear(in_features=1500,out_features=800)\n",
    "        self.fc3 = nn.Linear(800,400)\n",
    "        self.fc4 = nn.Linear(400,100)\n",
    "        self.fc5 = nn.Linear(100,10)\n",
    "        self.softmax = nn.functional.log_softmax\n",
    "        nn.init.xavier_uniform_(self.fc5.weight)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.relu(self.fc3(x))\n",
    "        x = nn.functional.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        out = self.softmax(x,dim=1)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0015\n",
    "batch_size = 256\n",
    "training_epochs = 25\n",
    "CNN_model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(CNN_model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of epoch 1 started\n",
      "[Epoch: 1   ] cost = 0.236 took 115.31373143196106s\n",
      "Training of epoch 2 started\n",
      "[Epoch: 2   ] cost = 0.0387 took 114.65327334403992s\n",
      "Training of epoch 3 started\n",
      "[Epoch: 3   ] cost = 0.0263 took 113.97079849243164s\n",
      "Training of epoch 4 started\n",
      "[Epoch: 4   ] cost = 0.0198 took 113.874835729599s\n",
      "Training of epoch 5 started\n",
      "[Epoch: 5   ] cost = 0.0141 took 114.50114679336548s\n",
      "Training of epoch 6 started\n",
      "[Epoch: 6   ] cost = 0.0125 took 132.70922207832336s\n",
      "Training of epoch 7 started\n",
      "[Epoch: 7   ] cost = 0.00967 took 128.55888104438782s\n",
      "Training of epoch 8 started\n",
      "[Epoch: 8   ] cost = 0.00665 took 134.20919823646545s\n",
      "Training of epoch 9 started\n",
      "[Epoch: 9   ] cost = 0.00585 took 136.073903799057s\n",
      "Training of epoch 10 started\n",
      "[Epoch: 10  ] cost = 0.00795 took 137.2274293899536s\n",
      "Training of epoch 11 started\n",
      "[Epoch: 11  ] cost = 0.00653 took 131.2337040901184s\n",
      "Training of epoch 12 started\n",
      "[Epoch: 12  ] cost = 0.00496 took 130.7832531929016s\n",
      "Training of epoch 13 started\n",
      "[Epoch: 13  ] cost = 0.00586 took 125.68407988548279s\n",
      "Training of epoch 14 started\n",
      "[Epoch: 14  ] cost = 0.00494 took 131.08425951004028s\n",
      "Training of epoch 15 started\n",
      "[Epoch: 15  ] cost = 0.00387 took 126.3575336933136s\n",
      "Training of epoch 16 started\n",
      "[Epoch: 16  ] cost = 0.00371 took 128.3707559108734s\n",
      "Training of epoch 17 started\n",
      "[Epoch: 17  ] cost = 0.00466 took 128.47571635246277s\n",
      "Training of epoch 18 started\n",
      "[Epoch: 18  ] cost = 0.00463 took 128.03141117095947s\n",
      "Training of epoch 19 started\n",
      "[Epoch: 19  ] cost = 0.00453 took 127.39447569847107s\n",
      "Training of epoch 20 started\n",
      "[Epoch: 20  ] cost = 0.00474 took 129.72487664222717s\n",
      "Training of epoch 21 started\n",
      "[Epoch: 21  ] cost = 0.00433 took 131.00223660469055s\n",
      "Training of epoch 22 started\n",
      "[Epoch: 22  ] cost = 0.0051 took 130.61185836791992s\n",
      "Training of epoch 23 started\n",
      "[Epoch: 23  ] cost = 0.00377 took 131.40690183639526s\n",
      "Training of epoch 24 started\n",
      "[Epoch: 24  ] cost = 0.00215 took 127.17182230949402s\n",
      "Training of epoch 25 started\n",
      "[Epoch: 25  ] cost = 0.00549 took 126.48555874824524s\n",
      "Learning Finished! in 3175.0276153087616s\n"
     ]
    }
   ],
   "source": [
    "training_time = time.time()\n",
    "for epochs in range(training_epochs):\n",
    "    print(\"Training of epoch {} started\".format(epochs+1))\n",
    "    avg_cost = 0\n",
    "    total_batch = len(X_train)//batch_size\n",
    "    start_time = time.time()\n",
    "    for inputs,labels in train_loader1:\n",
    "        optimizer.zero_grad()\n",
    "        output = CNN_model(inputs)\n",
    "        loss = criterion(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_cost+=loss.data/batch_size\n",
    "    print(\"[Epoch: {:<4}] cost = {:_<4.3} took {}s\".format(epochs + 1, avg_cost.item(),time.time()-start_time))\n",
    "\n",
    "print('Learning Finished! in {}s'.format(time.time()-training_time))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our model on test set using CNN architecture is  tensor(99.0148)\n"
     ]
    }
   ],
   "source": [
    "# Turn off gradients for validation\n",
    "test_loss1 = 0\n",
    "accuracy1 = 0\n",
    "with torch.no_grad():\n",
    "    CNN_model.eval()\n",
    "for images, labels in test_loader1:\n",
    "    out = CNN_model(images)\n",
    "    test_loss1 += criterion(out, labels)\n",
    "\n",
    "    ps = torch.exp(out)\n",
    "    # Get our top predictions\n",
    "    top_p, top_class = ps.topk(1, dim=1)\n",
    "    equals1 = top_class == labels.view(*top_class.shape)\n",
    "    accuracy1 += torch.mean(equals1.type(torch.FloatTensor))\n",
    "print(\"Accuracy of our model on test set using CNN architecture is \", (accuracy1/len(test_loader1))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type CNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(CNN_model,\"./Kaggle/digitrecognizerCNN.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelreloaded = torch.load(Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
